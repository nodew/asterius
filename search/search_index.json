{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"asterius is a Haskell to WebAssembly compiler. The project is in alpha stage and in active development. Sponsors Asterius is maintained by Tweag I/O . Have questions? Need help? Tweet at @tweagio .","title":"Home"},{"location":"#sponsors","text":"Asterius is maintained by Tweag I/O . Have questions? Need help? Tweet at @tweagio .","title":"Sponsors"},{"location":"ahc-link/","text":"Using ahc-link ahc-link is the frontend program of asterius compiler. It reads Haskell modules as inputs and generates one .wasm WebAssembly binary file and one .js stub loader script, which can be run in a Node.js or Chrome runtime. The help text of ahc-link is pasted here for your convenience: ahc-link - Linker for the Asterius compiler Usage: ahc-link [--browser] --input ARG [--output-wasm ARG] [--output-js ARG] [--output-html ARG] [--output-link-report ARG] [--output-graphviz ARG] [--js-bundle] [--binaryen] [--debug] [--output-ir] [--run] [--asterius-instance-callback ARG] [--ghc-option ARG] [--export-function ARG] [--extra-root-symbol ARG] Producing a standalone WebAssembly binary from Haskell Available options: --browser Target browsers instead of Node.js --input ARG Path of the Main module --output-wasm ARG Output path of WebAssembly binary, defaults to same path of Main --output-js ARG Output path of JavaScript, defaults to same path of Main. Must be the same directory as the WebAssembly binary. --output-html ARG Output path of HTML, defaults to same path of Main. Must be the same directory as the WebAssembly binary. --output-link-report ARG Output path of linking report --output-graphviz ARG Output path of GraphViz file of symbol dependencies --js-bundle Output a self-contained .js file --binaryen Use the binaryen backend --debug Enable debug mode in the runtime --output-ir Output Asterius IR of compiled modules --run Run the compiled module with Node.js --asterius-instance-callback ARG Supply a JavaScript callback expression which will be invoked on the initiated asterius instance. Defaults to calling Main.main --ghc-option ARG Extra GHC flags --export-function ARG Symbol of exported function --extra-root-symbol ARG Symbol of extra root entity, e.g. Main_f_closure -h,--help Show this help text","title":"Using ahc-link"},{"location":"ahc-link/#using-ahc-link","text":"ahc-link is the frontend program of asterius compiler. It reads Haskell modules as inputs and generates one .wasm WebAssembly binary file and one .js stub loader script, which can be run in a Node.js or Chrome runtime. The help text of ahc-link is pasted here for your convenience: ahc-link - Linker for the Asterius compiler Usage: ahc-link [--browser] --input ARG [--output-wasm ARG] [--output-js ARG] [--output-html ARG] [--output-link-report ARG] [--output-graphviz ARG] [--js-bundle] [--binaryen] [--debug] [--output-ir] [--run] [--asterius-instance-callback ARG] [--ghc-option ARG] [--export-function ARG] [--extra-root-symbol ARG] Producing a standalone WebAssembly binary from Haskell Available options: --browser Target browsers instead of Node.js --input ARG Path of the Main module --output-wasm ARG Output path of WebAssembly binary, defaults to same path of Main --output-js ARG Output path of JavaScript, defaults to same path of Main. Must be the same directory as the WebAssembly binary. --output-html ARG Output path of HTML, defaults to same path of Main. Must be the same directory as the WebAssembly binary. --output-link-report ARG Output path of linking report --output-graphviz ARG Output path of GraphViz file of symbol dependencies --js-bundle Output a self-contained .js file --binaryen Use the binaryen backend --debug Enable debug mode in the runtime --output-ir Output Asterius IR of compiled modules --run Run the compiled module with Node.js --asterius-instance-callback ARG Supply a JavaScript callback expression which will be invoked on the initiated asterius instance. Defaults to calling Main.main --ghc-option ARG Extra GHC flags --export-function ARG Symbol of exported function --extra-root-symbol ARG Symbol of extra root entity, e.g. Main_f_closure -h,--help Show this help text","title":"Using ahc-link"},{"location":"architecture/","text":"High-level architecture The asterius project is hosted at GitHub . The monorepo contains several packages: asterius . This is the central package of the asterius compiler. binaryen . It contains the latest source code of the C++ library binaryen in tree, and provides complete raw bindings to its C API . ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving ghc 's various types of in-memory intermediate representations. It also contains the latest source code of ghc-prim / integer-gmp / integer-simple / base in tree. wasm-toolkit . It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code. The asterius package provides an ahc executable which is a drop-in replacement of ghc to be used with Setup configure . ahc redirects all arguments to the real ghc most of the time, but when it's invoked with the --make major mode, it invokes ghc with its frontend plugin. This is inspired by Edward Yang's How to integrate GHC API programs with Cabal . Based on ghc-toolkit , asterius implements a ghc frontend plugin which translates Cmm to binaryen IR. The serialized binaryen IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected. About \"booting\" In order for asterius to support non-trivial Haskell programs (that is, at least most things in Prelude ), it needs to run the compilation process for base and its dependent packages. This process is known as \"booting\". The asterius package provides an ahc-boot test suite which tests booting by compiling the wired-in packages provided by ghc-toolkit and using ahc to replace ghc when configuring. This is inspired by Joachim Breitner's veggies .","title":"Project architecture"},{"location":"architecture/#high-level-architecture","text":"The asterius project is hosted at GitHub . The monorepo contains several packages: asterius . This is the central package of the asterius compiler. binaryen . It contains the latest source code of the C++ library binaryen in tree, and provides complete raw bindings to its C API . ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving ghc 's various types of in-memory intermediate representations. It also contains the latest source code of ghc-prim / integer-gmp / integer-simple / base in tree. wasm-toolkit . It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code. The asterius package provides an ahc executable which is a drop-in replacement of ghc to be used with Setup configure . ahc redirects all arguments to the real ghc most of the time, but when it's invoked with the --make major mode, it invokes ghc with its frontend plugin. This is inspired by Edward Yang's How to integrate GHC API programs with Cabal . Based on ghc-toolkit , asterius implements a ghc frontend plugin which translates Cmm to binaryen IR. The serialized binaryen IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected.","title":"High-level architecture"},{"location":"architecture/#about-booting","text":"In order for asterius to support non-trivial Haskell programs (that is, at least most things in Prelude ), it needs to run the compilation process for base and its dependent packages. This process is known as \"booting\". The asterius package provides an ahc-boot test suite which tests booting by compiling the wired-in packages provided by ghc-toolkit and using ahc to replace ghc when configuring. This is inspired by Joachim Breitner's veggies .","title":"About \"booting\""},{"location":"building/","text":"Building guide asterius is tested on Linux x64. Windows/macOS x64 may also work. A pre-built Docker image is provided for your convenience. Using a pre-built Docker image We build and test Docker images on CircleCI. They are pushed to terrorjack/asterius , the tags are git revisions. terrorjack/asterius:latest correspond to latest revision on master . Put input program in a directory (e.g. ~/mirror ), then map the directory to a Docker volume: terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius root@76bcb511663d:~# cd /mirror root@76bcb511663d:/mirror# ahc-link --help ... Building custom ghc asterius requires a forked ghc which can be found here . We are looking forward to building asterius with vanilla ghc-head in the long run, but at the moment, we use our own ghc fork so it's easy to test radical changes on ghc itself. The building guide of ghc can be found here . On Linux/macOS, a prebuilt ghc tarball is provided. It's already included in stack.yaml . Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction). Extra dependencies Besides the custom ghc , these dependencies are also required: cmake / make / g++ : For building in-tree binaryen autoconf : For booting ghc-prim / base nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support) stack : Someday cabal may also work, no specific obstacles anyway. Building asterius stack build asterius . That's it. Set MAKEFLAGS=-j8 to pass flags to make for parallel building of binaryen . After the dust settles, run stack exec ahc-boot to perform booting. Set the ASTERIUS_DEBUG environment variable to make ahc-boot print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!","title":"Building guide"},{"location":"building/#building-guide","text":"asterius is tested on Linux x64. Windows/macOS x64 may also work. A pre-built Docker image is provided for your convenience.","title":"Building guide"},{"location":"building/#using-a-pre-built-docker-image","text":"We build and test Docker images on CircleCI. They are pushed to terrorjack/asterius , the tags are git revisions. terrorjack/asterius:latest correspond to latest revision on master . Put input program in a directory (e.g. ~/mirror ), then map the directory to a Docker volume: terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius root@76bcb511663d:~# cd /mirror root@76bcb511663d:/mirror# ahc-link --help ...","title":"Using a pre-built Docker image"},{"location":"building/#building-custom-ghc","text":"asterius requires a forked ghc which can be found here . We are looking forward to building asterius with vanilla ghc-head in the long run, but at the moment, we use our own ghc fork so it's easy to test radical changes on ghc itself. The building guide of ghc can be found here . On Linux/macOS, a prebuilt ghc tarball is provided. It's already included in stack.yaml . Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction).","title":"Building custom ghc"},{"location":"building/#extra-dependencies","text":"Besides the custom ghc , these dependencies are also required: cmake / make / g++ : For building in-tree binaryen autoconf : For booting ghc-prim / base nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support) stack : Someday cabal may also work, no specific obstacles anyway.","title":"Extra dependencies"},{"location":"building/#building-asterius","text":"stack build asterius . That's it. Set MAKEFLAGS=-j8 to pass flags to make for parallel building of binaryen . After the dust settles, run stack exec ahc-boot to perform booting. Set the ASTERIUS_DEBUG environment variable to make ahc-boot print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!","title":"Building asterius"},{"location":"checklist/","text":"Checklist This page maintains a list of upcoming tasks for the project, each task with a brief explanation, estimation of difficulty/time and connections with other tasks. Ideally this should be called Roadmap instead of Checklist , but placing accurate milestones has proven to be hard. Towards a TodoMVC example The tasks listed in this section are all necessary ones to achieve a more \"real-world\" browser example like TodoMVC. They are currently being worked on. Implement foreign export javascript We already can call JavaScript from Haskell via foreign import javascript , for JavaScript to call into Haskell, we need to implement foreign export javascript . The exported Haskell functions will be available as WebAssembly exported functions, callable in JavaScript land. Requirements: Implement StablePtr , so that Haskell closures can be safely passed between Haskell/JavaScript boundary without being garbage collected. (done, see stableptr unit test) Implement RtsAPI , so that JavaScript code can create Haskell closures, trigger evaluation and inspect results. (done, see rtsapi unit test) Add StablePtr to JSFFI basic types. (done, see jsffi unit test) Implement foreign export javascript syntax, add necessary logic in JSFFI / Resolve (done, see jsffi unit test) Improve .wasm / .js generation Currently, given a home module, ahc-link outputs a .wasm and a .js wrapper which runs in Node.js. We will need the whole thing to run in browser though. Requirements: Add logic in ahc-link to generate browser-friendly code Make the test suite run via a headless browser, and properly retrieve results from the browser back to Haskell Next important tasks The following tasks are somewhat less important, but still necessary for end-user experience. They will be processed once the previous goal is accomplished. Improve Haskell/JavaScript marshalling Most JavaScript types will appear as opaque JSRef in Haskell land, but for some types that appear very often (e.g. strings and arrays), we wish they can be marshalled from/to their Haskell equivalents (e.g. lists) smoothly. Without this, even implementing a putStr will be troublesome because we must either send individual Char s to a TTY-device in JavaScript, or manually squeeze the string into a buffer in Haskell heap first. Requirements: Recognize String / [] as special JSFFI basic types, add marshalling logic from/to JavaScript strings/arrays. (in progress) When we support aeson in the future, it may even be possible to marshal between Value s and JavaScript objects directly. Support bytestring bytestring is a critical component in the Haskell ecosystem, we must support it regardless of what filthy hacks are deployed. At least non- Internal modules need to be supported. Requirements: Add bytestring to boot libs. Implement Weak# , since ByteString needs finalizers Implement WebAssembly shims in Builtins for required C functions. Utilize GHC renamer/typechecker in JSFFI Currently, the JSFFI thing works with parsed AST because it's less likely to mess up after rewriting. As a consequence: JSRef only works as a magic identifier. It's not in any actual Haskell module No newtypes for JSFFI basic types, since we recognize types by RdrName only We need to move JSFFI processing to the phase of renamer or typechecker. Support JavaScript promises in JSFFI The foreign import javascript syntax currently assumes the JavaScript computation is synchronous. We need to support asynchronous JavaScript computation, by adding a foreign import javascript safe construct, and assume the JavaScript computation returns a Promise . Upon calling such a function, the scheduler saves thread state and gracefully halts the whole runtime. The runtime will be re-activated once the Promise is fulfilled. Add growable heap/garbage collection to storage manager Currently, the heap size is fixed and can be specified by ahc-link --heap-size . By defaulting a heap size of 1GB, we pretend memory is infinite and focus work on other issues, but this can come back to bite us at any time. There are two steps in this tasks: Implement growable heap. When GC is entered, we allocate fresh blocks and move the nursery/object pool to point to new blocks. Implement garbage collection. Porting all GC routines is a huge amount of work and error-prone, so we implement a non-generational one in JavaScript. Solve reference leaking in JSFFI JSRef is implemented much like StablePtr : a mapping from handles to objects. Whenever a JSRef enters Haskell land, the underlying object is pointed to by a mapping, but currently there's no mechanism to free a JSRef . Some possible fixes: Provide freeJSRef in Haskell land, works for any individual JSRef Provide nukeJSRefs , can be called periodically to wipe all JSRef s Provide a region-based API, all JSRef s are tied to a region. Regions themselves can be allocated and recycled. Optionally there can be a global region. Support 3rd-party GHC plugins Currently there exist multiple plugin mechanisms in GHC: Frontend plugins, allowing one to create a custom major mode and execute custom login in the Ghc monad when the ghc process is called. GHC only does the work of parsing command line arguments. Core plugins, allowing one to modify the Core -> Core pipeline and insert custom passes. Source plugins, allowing one to inspect/modify the parsed/renamed/typechecked AST. Hooks, allowing one to override certain GHC internal functions. We should add tests to ensure 3rd-party GHC plugins work. For Core plugins: we don't manipulate Core, so they should work out of the box. For Source plugins: the JSFFI mechanism relies on rewriting AST (currently parsed AST), but via runPhaseHook instead of source plugins, so this may work but needs some testing. For Frontend plugins: to support a frontend plugin, work must be done on the plugin side instead of here, since the main logic is handled by plugin itself. Not practical since we use hooks to implement our modified pipeline, which is likely to be hard to integrated into another pipeline. For Hooks: Not practical, reason is the same as above. Implement Template Haskell/GHCi There are two possible ways to implement Template Haskell: Link with the native code produced when booting. For simple Q computations that doesn't involve runIO this should work fine, but it won't work when one calls a WebAssembly computation in Q . Implement the remote interpreter for WebAssembly, much like ghcjs. When Template Haskell/GHCi is involved, we fire up a Node.js/Headless Chrome process and do all the message passing. This is the ideal solution but takes a huge amount of work. Implementing the first approach seems straightforward: While we compile to WebAssembly, we still perform native code generation and emit x64 object files. The emitted object files are just there to make Cabal happy, but GHCi linker may take advantage of them. As long as GHCi linker doesn't fail, the computation in Q monad can be executed in the ahc process. It's not run in a JavaScript runtime properly, so the splice's module must not have any transitive dependency on a JSFFI import (GHCi linking will fail anyway). However, even for simple splices, the GHCi linker raises a lot of unresolved symbol errors like this: ahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `stg_word32ToFloatzh' ahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `base_GHCziFloat_zdfRealFloatDouble2_closure' The ELF object files are not corrupt, but a lot of places assume the unit id of base is simply base , however the base package compiled by ahc-boot has a different unit id to avoid collision with the host ghc's base . Patching the object files may be a valid workaround here, but I question if it's worth the effort. Improve Cabal support Currently, Cabal still thinks ahc is yet another ghc and feeds it with ghc command line arguments. We should teach it to regard ahc as a new Haskell compiler, and what to do for typical commands ( configure / build / install , etc). After Cabal support is improved, we can: Get away with current \"boot libs\" mechanism, instead rely on regular GHC package databases Give users ability to build/use packages outside boot libs Go on with improving cabal-install , some day a plain cabal build --asterius may work Improve test suite The current test suites have poor coverage of Haskell features. Archived tasks The following tasks have lower priority, either due to low impact to end-user experience or significant time involved. They are archived here and may be revisited at a later date, and we're still happy to discuss or review a pull request. Improve WebAssembly EDSL We already have a monadic EDSL for constructing WebAssembly code. There are still minor flaws with current EDSL: No notion of struct s. We manually load/store via a base pointer and an offset. Not type-safe. It's possible to mix-up I32 / I64 stuff and it's not always possible for binaryen validator to catch the problem (especially when load/store is involved) Global/static variables need a lot of boilerplate Switch away from binaryen binaryen is a fantastic library for WebAssembly code generation and has powered asterius since the beginning. However, there are reasons to switch away and implement our own WebAssembly code generation library: The relooper has been a constant source of trouble. We already implement our own relooper now. There's no support for linking and symbol resolution, so we have to keep two sets of types for WebAssembly: one is our own for pre-linking modules, one is the final linked data to feed to binaryen , but they overlap a lot. binaryen is conservative in features. We'd like to try experimental WebAssembly features (exception handling, multi-return, anyref, etc) in V8. Integrate LLVM/Clang or Emscripten It's a shame we can't compile simple cbits in Haskell packages and have to hand-write WebAssembly code instead. Implement \"Try asterius\" website To increase momentum for this project, it'd be nice to have a \"try asterius\" website, where people can send snippets of modules and download compiled code to run in their browsers. Add macOS support Currently we don't build GHC bindists for macOS and test it on CircleCI. For the sake of macOS Haskellers this should be implemented. Add Nix/Bazel support It'd be nice to support building the project via Nix/Bazel. Support integer-gmp We currently use integer-simple , but not all packages implement the flags to switch away from integer-gmp . It's worth mentioning that V8 already has experimental support for the BigInt proposal, so Integer s should ideally be powered by bigint s under the hood. Support tables-next-to-code Of course, we know the WebAssembly standard separates data and code, so something like tables-next-to-code won't work; but come to think of it, at link time we already know the absolute addresses of \"code\", so we can cheat a little bit here.. If we support both integer-gmp and tables-next-to-code, we can stop requiring users to set up a custom GHC first, and can distribute asterius as a vanilla package.","title":"Checklist"},{"location":"checklist/#checklist","text":"This page maintains a list of upcoming tasks for the project, each task with a brief explanation, estimation of difficulty/time and connections with other tasks. Ideally this should be called Roadmap instead of Checklist , but placing accurate milestones has proven to be hard.","title":"Checklist"},{"location":"checklist/#towards-a-todomvc-example","text":"The tasks listed in this section are all necessary ones to achieve a more \"real-world\" browser example like TodoMVC. They are currently being worked on.","title":"Towards a TodoMVC example"},{"location":"checklist/#implement-foreign-export-javascript","text":"We already can call JavaScript from Haskell via foreign import javascript , for JavaScript to call into Haskell, we need to implement foreign export javascript . The exported Haskell functions will be available as WebAssembly exported functions, callable in JavaScript land. Requirements: Implement StablePtr , so that Haskell closures can be safely passed between Haskell/JavaScript boundary without being garbage collected. (done, see stableptr unit test) Implement RtsAPI , so that JavaScript code can create Haskell closures, trigger evaluation and inspect results. (done, see rtsapi unit test) Add StablePtr to JSFFI basic types. (done, see jsffi unit test) Implement foreign export javascript syntax, add necessary logic in JSFFI / Resolve (done, see jsffi unit test)","title":"Implement foreign export javascript"},{"location":"checklist/#improve-wasmjs-generation","text":"Currently, given a home module, ahc-link outputs a .wasm and a .js wrapper which runs in Node.js. We will need the whole thing to run in browser though. Requirements: Add logic in ahc-link to generate browser-friendly code Make the test suite run via a headless browser, and properly retrieve results from the browser back to Haskell","title":"Improve .wasm/.js generation"},{"location":"checklist/#next-important-tasks","text":"The following tasks are somewhat less important, but still necessary for end-user experience. They will be processed once the previous goal is accomplished.","title":"Next important tasks"},{"location":"checklist/#improve-haskelljavascript-marshalling","text":"Most JavaScript types will appear as opaque JSRef in Haskell land, but for some types that appear very often (e.g. strings and arrays), we wish they can be marshalled from/to their Haskell equivalents (e.g. lists) smoothly. Without this, even implementing a putStr will be troublesome because we must either send individual Char s to a TTY-device in JavaScript, or manually squeeze the string into a buffer in Haskell heap first. Requirements: Recognize String / [] as special JSFFI basic types, add marshalling logic from/to JavaScript strings/arrays. (in progress) When we support aeson in the future, it may even be possible to marshal between Value s and JavaScript objects directly.","title":"Improve Haskell/JavaScript marshalling"},{"location":"checklist/#support-bytestring","text":"bytestring is a critical component in the Haskell ecosystem, we must support it regardless of what filthy hacks are deployed. At least non- Internal modules need to be supported. Requirements: Add bytestring to boot libs. Implement Weak# , since ByteString needs finalizers Implement WebAssembly shims in Builtins for required C functions.","title":"Support bytestring"},{"location":"checklist/#utilize-ghc-renamertypechecker-in-jsffi","text":"Currently, the JSFFI thing works with parsed AST because it's less likely to mess up after rewriting. As a consequence: JSRef only works as a magic identifier. It's not in any actual Haskell module No newtypes for JSFFI basic types, since we recognize types by RdrName only We need to move JSFFI processing to the phase of renamer or typechecker.","title":"Utilize GHC renamer/typechecker in JSFFI"},{"location":"checklist/#support-javascript-promises-in-jsffi","text":"The foreign import javascript syntax currently assumes the JavaScript computation is synchronous. We need to support asynchronous JavaScript computation, by adding a foreign import javascript safe construct, and assume the JavaScript computation returns a Promise . Upon calling such a function, the scheduler saves thread state and gracefully halts the whole runtime. The runtime will be re-activated once the Promise is fulfilled.","title":"Support JavaScript promises in JSFFI"},{"location":"checklist/#add-growable-heapgarbage-collection-to-storage-manager","text":"Currently, the heap size is fixed and can be specified by ahc-link --heap-size . By defaulting a heap size of 1GB, we pretend memory is infinite and focus work on other issues, but this can come back to bite us at any time. There are two steps in this tasks: Implement growable heap. When GC is entered, we allocate fresh blocks and move the nursery/object pool to point to new blocks. Implement garbage collection. Porting all GC routines is a huge amount of work and error-prone, so we implement a non-generational one in JavaScript.","title":"Add growable heap/garbage collection to storage manager"},{"location":"checklist/#solve-reference-leaking-in-jsffi","text":"JSRef is implemented much like StablePtr : a mapping from handles to objects. Whenever a JSRef enters Haskell land, the underlying object is pointed to by a mapping, but currently there's no mechanism to free a JSRef . Some possible fixes: Provide freeJSRef in Haskell land, works for any individual JSRef Provide nukeJSRefs , can be called periodically to wipe all JSRef s Provide a region-based API, all JSRef s are tied to a region. Regions themselves can be allocated and recycled. Optionally there can be a global region.","title":"Solve reference leaking in JSFFI"},{"location":"checklist/#support-3rd-party-ghc-plugins","text":"Currently there exist multiple plugin mechanisms in GHC: Frontend plugins, allowing one to create a custom major mode and execute custom login in the Ghc monad when the ghc process is called. GHC only does the work of parsing command line arguments. Core plugins, allowing one to modify the Core -> Core pipeline and insert custom passes. Source plugins, allowing one to inspect/modify the parsed/renamed/typechecked AST. Hooks, allowing one to override certain GHC internal functions. We should add tests to ensure 3rd-party GHC plugins work. For Core plugins: we don't manipulate Core, so they should work out of the box. For Source plugins: the JSFFI mechanism relies on rewriting AST (currently parsed AST), but via runPhaseHook instead of source plugins, so this may work but needs some testing. For Frontend plugins: to support a frontend plugin, work must be done on the plugin side instead of here, since the main logic is handled by plugin itself. Not practical since we use hooks to implement our modified pipeline, which is likely to be hard to integrated into another pipeline. For Hooks: Not practical, reason is the same as above.","title":"Support 3rd-party GHC plugins"},{"location":"checklist/#implement-template-haskellghci","text":"There are two possible ways to implement Template Haskell: Link with the native code produced when booting. For simple Q computations that doesn't involve runIO this should work fine, but it won't work when one calls a WebAssembly computation in Q . Implement the remote interpreter for WebAssembly, much like ghcjs. When Template Haskell/GHCi is involved, we fire up a Node.js/Headless Chrome process and do all the message passing. This is the ideal solution but takes a huge amount of work. Implementing the first approach seems straightforward: While we compile to WebAssembly, we still perform native code generation and emit x64 object files. The emitted object files are just there to make Cabal happy, but GHCi linker may take advantage of them. As long as GHCi linker doesn't fail, the computation in Q monad can be executed in the ahc process. It's not run in a JavaScript runtime properly, so the splice's module must not have any transitive dependency on a JSFFI import (GHCi linking will fail anyway). However, even for simple splices, the GHCi linker raises a lot of unresolved symbol errors like this: ahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `stg_word32ToFloatzh' ahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `base_GHCziFloat_zdfRealFloatDouble2_closure' The ELF object files are not corrupt, but a lot of places assume the unit id of base is simply base , however the base package compiled by ahc-boot has a different unit id to avoid collision with the host ghc's base . Patching the object files may be a valid workaround here, but I question if it's worth the effort.","title":"Implement Template Haskell/GHCi"},{"location":"checklist/#improve-cabal-support","text":"Currently, Cabal still thinks ahc is yet another ghc and feeds it with ghc command line arguments. We should teach it to regard ahc as a new Haskell compiler, and what to do for typical commands ( configure / build / install , etc). After Cabal support is improved, we can: Get away with current \"boot libs\" mechanism, instead rely on regular GHC package databases Give users ability to build/use packages outside boot libs Go on with improving cabal-install , some day a plain cabal build --asterius may work","title":"Improve Cabal support"},{"location":"checklist/#improve-test-suite","text":"The current test suites have poor coverage of Haskell features.","title":"Improve test suite"},{"location":"checklist/#archived-tasks","text":"The following tasks have lower priority, either due to low impact to end-user experience or significant time involved. They are archived here and may be revisited at a later date, and we're still happy to discuss or review a pull request.","title":"Archived tasks"},{"location":"checklist/#improve-webassembly-edsl","text":"We already have a monadic EDSL for constructing WebAssembly code. There are still minor flaws with current EDSL: No notion of struct s. We manually load/store via a base pointer and an offset. Not type-safe. It's possible to mix-up I32 / I64 stuff and it's not always possible for binaryen validator to catch the problem (especially when load/store is involved) Global/static variables need a lot of boilerplate","title":"Improve WebAssembly EDSL"},{"location":"checklist/#switch-away-from-binaryen","text":"binaryen is a fantastic library for WebAssembly code generation and has powered asterius since the beginning. However, there are reasons to switch away and implement our own WebAssembly code generation library: The relooper has been a constant source of trouble. We already implement our own relooper now. There's no support for linking and symbol resolution, so we have to keep two sets of types for WebAssembly: one is our own for pre-linking modules, one is the final linked data to feed to binaryen , but they overlap a lot. binaryen is conservative in features. We'd like to try experimental WebAssembly features (exception handling, multi-return, anyref, etc) in V8.","title":"Switch away from binaryen"},{"location":"checklist/#integrate-llvmclang-or-emscripten","text":"It's a shame we can't compile simple cbits in Haskell packages and have to hand-write WebAssembly code instead.","title":"Integrate LLVM/Clang or Emscripten"},{"location":"checklist/#implement-try-asterius-website","text":"To increase momentum for this project, it'd be nice to have a \"try asterius\" website, where people can send snippets of modules and download compiled code to run in their browsers.","title":"Implement \"Try asterius\" website"},{"location":"checklist/#add-macos-support","text":"Currently we don't build GHC bindists for macOS and test it on CircleCI. For the sake of macOS Haskellers this should be implemented.","title":"Add macOS support"},{"location":"checklist/#add-nixbazel-support","text":"It'd be nice to support building the project via Nix/Bazel.","title":"Add Nix/Bazel support"},{"location":"checklist/#support-integer-gmp","text":"We currently use integer-simple , but not all packages implement the flags to switch away from integer-gmp . It's worth mentioning that V8 already has experimental support for the BigInt proposal, so Integer s should ideally be powered by bigint s under the hood.","title":"Support integer-gmp"},{"location":"checklist/#support-tables-next-to-code","text":"Of course, we know the WebAssembly standard separates data and code, so something like tables-next-to-code won't work; but come to think of it, at link time we already know the absolute addresses of \"code\", so we can cheat a little bit here.. If we support both integer-gmp and tables-next-to-code, we can stop requiring users to set up a custom GHC first, and can distribute asterius as a vanilla package.","title":"Support tables-next-to-code"},{"location":"custom-ghc/","text":"About the custom GHC fork Asterius currently is based on a custom GHC fork maintained here . We regularly merge master commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back. Here is a complete list of differences we've made in the fork (surprisingly few at the moment): Enable D5079 and D5082 , which are kindly offered by Joachim Breitner but not all landed in master yet. Implement additional Hooks : tcRnModuleHook , stgCmmHook , cmmToRawCmmHook . Link ghc-pkg / hsc2hs with -threaded . See the circleci-ghc-bindist / appveyor-ghc-bindist branches of asterius repo for CI scripts to build bindists for the fork. The AppVeyor script is broken for now.","title":"About the custom GHC fork"},{"location":"custom-ghc/#about-the-custom-ghc-fork","text":"Asterius currently is based on a custom GHC fork maintained here . We regularly merge master commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back. Here is a complete list of differences we've made in the fork (surprisingly few at the moment): Enable D5079 and D5082 , which are kindly offered by Joachim Breitner but not all landed in master yet. Implement additional Hooks : tcRnModuleHook , stgCmmHook , cmmToRawCmmHook . Link ghc-pkg / hsc2hs with -threaded . See the circleci-ghc-bindist / appveyor-ghc-bindist branches of asterius repo for CI scripts to build bindists for the fork. The AppVeyor script is broken for now.","title":"About the custom GHC fork"},{"location":"debugging/","text":"The runtime debugging feature There is a runtime debugging mode which can be enabled by the --debug flag for ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places: The start of a function/basic block SetLocal when the local type is I64 Memory load/stores, when the value type is I64 The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the --output-link-report flag to dump the linking report, which contains mapping from data/function symbols to addresses. The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!) Virtual address spaces Remember that we're compiling to wasm32 which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon load / store / call_indirect , we truncate the 64-bit pointer, using only the lower 32-bits for indexing. The higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between: The physical address, which is either an i32 index of the linear memory for data, or an i32 index of the table for functions. The logical address, which is the i64 pointer value we're passing around. All access to the memory/table is achieved by using the logical address. The access operations are accompanied by a mapping operation which translates a logical address to a physical one. Currently it's just a truncate, but in the future we may get a more feature-complete mmap / munmap implementation, and some additional computation may occur when address translation is done. We chose two magic numbers (in Asterius.Internals.MagicNumber ) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the logical address does not exceed JavaScript's safe integer limit. When we emit debug log entries, we may encounter various i64 values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate i64 value in a Haskell computation accidently collides with a logical address) may exist in theory, but the probability should be very low. Note that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning. Complete list of emitted debugging log entries Assertions: some hand-written WebAssembly functions in Asterius.Builtins contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted. Memory traps: In Asterius.MemoryTrap , we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in Asterius.Builtins , which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc). Control-flow: In Asterius.Tracing , we implement a rewriting pass on functions (which are later invoked at link-time in Asterius.Resolve ), which emits messages when: Entering a Cmm function. Entering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure) Assigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here. Dumping IRs There are multiple ways to dump IRs: Via GHC flags: GHC flags like -ddump-to-file -ddump-cmm-raw dump pretty-printed GHC IRs to files. Via environment variable: Set the ASTERIUS_DEBUG environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped. Via ahc-link flag: Use ahc-link --output-ir to dump IRs when compiling user code.","title":"The runtime debugging feature"},{"location":"debugging/#the-runtime-debugging-feature","text":"There is a runtime debugging mode which can be enabled by the --debug flag for ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places: The start of a function/basic block SetLocal when the local type is I64 Memory load/stores, when the value type is I64 The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the --output-link-report flag to dump the linking report, which contains mapping from data/function symbols to addresses. The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!)","title":"The runtime debugging feature"},{"location":"debugging/#virtual-address-spaces","text":"Remember that we're compiling to wasm32 which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon load / store / call_indirect , we truncate the 64-bit pointer, using only the lower 32-bits for indexing. The higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between: The physical address, which is either an i32 index of the linear memory for data, or an i32 index of the table for functions. The logical address, which is the i64 pointer value we're passing around. All access to the memory/table is achieved by using the logical address. The access operations are accompanied by a mapping operation which translates a logical address to a physical one. Currently it's just a truncate, but in the future we may get a more feature-complete mmap / munmap implementation, and some additional computation may occur when address translation is done. We chose two magic numbers (in Asterius.Internals.MagicNumber ) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the logical address does not exceed JavaScript's safe integer limit. When we emit debug log entries, we may encounter various i64 values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate i64 value in a Haskell computation accidently collides with a logical address) may exist in theory, but the probability should be very low. Note that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning.","title":"Virtual address spaces"},{"location":"debugging/#complete-list-of-emitted-debugging-log-entries","text":"Assertions: some hand-written WebAssembly functions in Asterius.Builtins contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted. Memory traps: In Asterius.MemoryTrap , we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in Asterius.Builtins , which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc). Control-flow: In Asterius.Tracing , we implement a rewriting pass on functions (which are later invoked at link-time in Asterius.Resolve ), which emits messages when: Entering a Cmm function. Entering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure) Assigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here.","title":"Complete list of emitted debugging log entries"},{"location":"debugging/#dumping-irs","text":"There are multiple ways to dump IRs: Via GHC flags: GHC flags like -ddump-to-file -ddump-cmm-raw dump pretty-printed GHC IRs to files. Via environment variable: Set the ASTERIUS_DEBUG environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped. Via ahc-link flag: Use ahc-link --output-ir to dump IRs when compiling user code.","title":"Dumping IRs"},{"location":"ir/","text":"IR types and transformation passes This section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in jsffi.md which explains implementation details of JSFFI) Cmm IR Everything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies: All calls are tail calls, parameters are passed by global registers like R1 or on the stack. All info tables are converted to binary data segments. Check Cmm module in ghc package to get started on Cmm. Asterius obtains in-memory raw Cmm via: cmmToRawCmmHook in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or .cmm files (which are in rts ) There is some abstraction in ghc-toolkit , the compiler logic is actually in the Compiler datatype as some callbacks, and ghc-toolkit converts them to hooks, frontend plugins and ghc executable wrappers. There is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first. Pre-linking expression IR We then marshal raw Cmm to an expression IR defined in Asterius.Types . Each compilation unit (Haskell module or .cmm file) maps to one AsteriusModule , and each AsteriusModule is serialized to a .asterius_o object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now. The expression IR is mostly a Haskell modeling of a subset of binaryen 's expression IR, with some additions: Unresolved related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses. Unresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's StgRegTable . EmitErrorMessage , as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\". Null . We're civilized, educated functional programmers and should really be using Maybe Expression in some fields instead of adding a Null constructor, but this is just handy. Blame me. It's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So AsteriusModule also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard) The symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units. The store There's an AsteriusStore type in Asterius.Types . It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker. Modeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in Asterius.Store which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module. AsteriusStore supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store. Post-linking expression IR At link time, we take AsteriusStore which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like Main_main_closure ), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module. We then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in Asterius.Resolve . The output of linker is Module . It differs from AsteriusModule , and although it shares quite some datatypes with AsteriusModule (for example, Expression ), it guarantees that some variants will not appear (for example, Unresolved* ). A Module is ready to be fed to a backend which emits real wasm binary code. There are some useful linker byproducts. For example, there's LinkReport which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging. Generating binary code via binaryen Once we have a Module (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the binaryen package, and Asterius.Marshal contains the logic to call the imported functions to do actual work. Generating binary code via wasm-toolkit We can also convert Module to IR types of wasm-toolkit , which is our native Haskell wasm engine. It's now the default backend of ahc-link , but the binaryen backend can still be chosen by ahc-link --binaryen . Generating JavaScript stub script To make it actually run in Node.js/Chrome, we need two pieces of JavaScript code: Common runtime which can be reused across different asterius compiled modules. It's in asterius/rts/rts.js . Stub code which contains specific information like error messages, etc. The linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via ahc-link flags.","title":"IR types and transformation passes"},{"location":"ir/#ir-types-and-transformation-passes","text":"This section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in jsffi.md which explains implementation details of JSFFI)","title":"IR types and transformation passes"},{"location":"ir/#cmm-ir","text":"Everything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies: All calls are tail calls, parameters are passed by global registers like R1 or on the stack. All info tables are converted to binary data segments. Check Cmm module in ghc package to get started on Cmm. Asterius obtains in-memory raw Cmm via: cmmToRawCmmHook in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or .cmm files (which are in rts ) There is some abstraction in ghc-toolkit , the compiler logic is actually in the Compiler datatype as some callbacks, and ghc-toolkit converts them to hooks, frontend plugins and ghc executable wrappers. There is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first.","title":"Cmm IR"},{"location":"ir/#pre-linking-expression-ir","text":"We then marshal raw Cmm to an expression IR defined in Asterius.Types . Each compilation unit (Haskell module or .cmm file) maps to one AsteriusModule , and each AsteriusModule is serialized to a .asterius_o object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now. The expression IR is mostly a Haskell modeling of a subset of binaryen 's expression IR, with some additions: Unresolved related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses. Unresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's StgRegTable . EmitErrorMessage , as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\". Null . We're civilized, educated functional programmers and should really be using Maybe Expression in some fields instead of adding a Null constructor, but this is just handy. Blame me. It's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So AsteriusModule also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard) The symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units.","title":"Pre-linking expression IR"},{"location":"ir/#the-store","text":"There's an AsteriusStore type in Asterius.Types . It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker. Modeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in Asterius.Store which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module. AsteriusStore supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store.","title":"The store"},{"location":"ir/#post-linking-expression-ir","text":"At link time, we take AsteriusStore which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like Main_main_closure ), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module. We then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in Asterius.Resolve . The output of linker is Module . It differs from AsteriusModule , and although it shares quite some datatypes with AsteriusModule (for example, Expression ), it guarantees that some variants will not appear (for example, Unresolved* ). A Module is ready to be fed to a backend which emits real wasm binary code. There are some useful linker byproducts. For example, there's LinkReport which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging.","title":"Post-linking expression IR"},{"location":"ir/#generating-binary-code-via-binaryen","text":"Once we have a Module (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the binaryen package, and Asterius.Marshal contains the logic to call the imported functions to do actual work.","title":"Generating binary code via binaryen"},{"location":"ir/#generating-binary-code-via-wasm-toolkit","text":"We can also convert Module to IR types of wasm-toolkit , which is our native Haskell wasm engine. It's now the default backend of ahc-link , but the binaryen backend can still be chosen by ahc-link --binaryen .","title":"Generating binary code via wasm-toolkit"},{"location":"ir/#generating-javascript-stub-script","text":"To make it actually run in Node.js/Chrome, we need two pieces of JavaScript code: Common runtime which can be reused across different asterius compiled modules. It's in asterius/rts/rts.js . Stub code which contains specific information like error messages, etc. The linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via ahc-link flags.","title":"Generating JavaScript stub script"},{"location":"jsffi/","text":"JavaScript FFI There is a prototype implementation of foreign import javascript right now, check the jsffi / teletype unit tests for details. The syntax is like: import Asterius.Types foreign import javascript \"new Date()\" current_time :: IO JSVal foreign import javascript \"console.log(${1})\" js_print :: JSVal -> IO () The source text of foreign import javascript should be a valid JavaScript expression. You can use ${n} to refer to the nth function parameter starting from 1. By using the IIFE(Immediately Invoked Function Expression) design pattern, it's even possible to define local variables and write for loops. Supported basic types are: Ptr FunPtr StablePtr Bool Int Word Char Float Double JSVal / JSArrayBuffer / JSString / JSArray For the lifted basic types, the result can be wrapped in IO (or not). There's also limited support for unlifted FFI types: StablePtr# a Addr# ByteArray# MutableByteArray# s Char# Int# Word# Float# Double# These unlifted FFI types can be used in a foreign import javascript clause (but not export .) The results can't be wrapped in IO . JSVal is defined in Asterius.Types in the patched ghc-prim package. In the Haskell land, JSVal is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects. Normally, the Haskell FFI mechanism permits defining newtype s to the marshallable basic types, and the wrapping/unwrapping is done automatically. However, this doesn't work yet due to the way we implement JSFFI right now. You can define a newtype to JSVal / JSWhatever , but in a foreign import javascript / foreign export javascript declaration, you still must use one of the builtin JS* types, and when using imported functions, you need to manually coerce them ( coerce works when Asterius.Types is imported). Also, a prototype of foreign export javascript is implemented, check jsffi for details. The syntax is roughly: foreign export javascript \"mult_hs\" (*) :: Int -> Int -> Int In a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify ahc-link --export-function=mult_hs to make the linker include the relevant bits in final WebAssembly binary, and export mult_hs as a regular WebAssembly export function. After calling hs_init to initialize the runtime, one can call mult_hs just like a regular JavaScript function. Converting between Haskell and JavaScript types The Asterius.Types / Asterius.ByteString modules provide some high-level functions for converting between Haskell and JavaScript types: fromJSString :: JSString -> [Char] toJSString :: [Char] -> JSString fromJSArray :: JSArray -> [JSVal] toJSArray :: [JSVal] -> JSArray byteStringFromJSArrayBuffer :: JSArrayBuffer -> ByteString byteStringToJSArrayBuffer :: ByteString -> JSArrayBuffer It's possible to define them just by using the basic JSFFI mechanism, but those functions are backed by special runtime interfaces which makes them a lot faster. Most notably, the fromJS* functions directly traverse the JavaScript value and build a fully-evaluated Haskell data structure on the heap in one pass. What's permitted in foreign import javascript In a foreign import javascript declaration, you can access all properties of the global object ( window in browsers, global in node.js), so all functionalities of standard JavaScript is permitted. Additionally, the __asterius_jsffi object is in scope; it is initialized before instantiating the WebAssembly instance, and contains the runtime interfaces used to support the JSFFI features (e.g. manipulation of JSVal s). You may check rts/rts.js to see what __asterius_jsffi contains, but we don't recommend using it in your code since it's intended to be an implementation detail; shall you feel the need to access it, please file an issue instead and we'll add your missing functionality as proper Haskell/JavaScript interfaces instead. Implementation This subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code. It's not a required reading for users of the JSFFI feature. Syntactic sugar As documented in previous sections, one can write foreign import javascript or foreign export javascript clauses in a .hs module. How are they processed? The logic resides in Asterius.JSFFI . First, there is addFFIProcessor , which given a Compiler (defined in ghc-toolkit ), returns a new Compiler and a callback to fetch a stub module. The details of Compiler 's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API. addFFIProcessor adds one functionality to the input Compiler : rewrite parsed Haskell AST and handle the foreign import javascript / foreign export javascript syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal. After the parsed AST is processed, a \"stub module\" of type AsteriusModule is generated and can be later fetched given an AsteriusModuleSymbol . It contains JSFFI related information of type FFIMarshalState . Both AsteriusModule and FFIMarshalState types has Semigroup instance so they can be combined later at link-time. TODO Adding a JSFFI basic type Look at the following places: Asterius.JSFFI module. All JavaScript reference types are uniformly handled as FFI_JSREF , while value types are treated as FFI_VAL . Assuming we are adding a value type. Add logic to: marshalToFFIValueType : Recognize the value type in parsed AST, and translate to FFI_VAL Asterius.Builtins module. Add the corresponding rts_mkXX / rts_getXX builtin functions. They are required for stub functions of foreign export javascript .","title":"JavaScript FFI"},{"location":"jsffi/#javascript-ffi","text":"There is a prototype implementation of foreign import javascript right now, check the jsffi / teletype unit tests for details. The syntax is like: import Asterius.Types foreign import javascript \"new Date()\" current_time :: IO JSVal foreign import javascript \"console.log(${1})\" js_print :: JSVal -> IO () The source text of foreign import javascript should be a valid JavaScript expression. You can use ${n} to refer to the nth function parameter starting from 1. By using the IIFE(Immediately Invoked Function Expression) design pattern, it's even possible to define local variables and write for loops. Supported basic types are: Ptr FunPtr StablePtr Bool Int Word Char Float Double JSVal / JSArrayBuffer / JSString / JSArray For the lifted basic types, the result can be wrapped in IO (or not). There's also limited support for unlifted FFI types: StablePtr# a Addr# ByteArray# MutableByteArray# s Char# Int# Word# Float# Double# These unlifted FFI types can be used in a foreign import javascript clause (but not export .) The results can't be wrapped in IO . JSVal is defined in Asterius.Types in the patched ghc-prim package. In the Haskell land, JSVal is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects. Normally, the Haskell FFI mechanism permits defining newtype s to the marshallable basic types, and the wrapping/unwrapping is done automatically. However, this doesn't work yet due to the way we implement JSFFI right now. You can define a newtype to JSVal / JSWhatever , but in a foreign import javascript / foreign export javascript declaration, you still must use one of the builtin JS* types, and when using imported functions, you need to manually coerce them ( coerce works when Asterius.Types is imported). Also, a prototype of foreign export javascript is implemented, check jsffi for details. The syntax is roughly: foreign export javascript \"mult_hs\" (*) :: Int -> Int -> Int In a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify ahc-link --export-function=mult_hs to make the linker include the relevant bits in final WebAssembly binary, and export mult_hs as a regular WebAssembly export function. After calling hs_init to initialize the runtime, one can call mult_hs just like a regular JavaScript function.","title":"JavaScript FFI"},{"location":"jsffi/#converting-between-haskell-and-javascript-types","text":"The Asterius.Types / Asterius.ByteString modules provide some high-level functions for converting between Haskell and JavaScript types: fromJSString :: JSString -> [Char] toJSString :: [Char] -> JSString fromJSArray :: JSArray -> [JSVal] toJSArray :: [JSVal] -> JSArray byteStringFromJSArrayBuffer :: JSArrayBuffer -> ByteString byteStringToJSArrayBuffer :: ByteString -> JSArrayBuffer It's possible to define them just by using the basic JSFFI mechanism, but those functions are backed by special runtime interfaces which makes them a lot faster. Most notably, the fromJS* functions directly traverse the JavaScript value and build a fully-evaluated Haskell data structure on the heap in one pass.","title":"Converting between Haskell and JavaScript types"},{"location":"jsffi/#whats-permitted-in-foreign-import-javascript","text":"In a foreign import javascript declaration, you can access all properties of the global object ( window in browsers, global in node.js), so all functionalities of standard JavaScript is permitted. Additionally, the __asterius_jsffi object is in scope; it is initialized before instantiating the WebAssembly instance, and contains the runtime interfaces used to support the JSFFI features (e.g. manipulation of JSVal s). You may check rts/rts.js to see what __asterius_jsffi contains, but we don't recommend using it in your code since it's intended to be an implementation detail; shall you feel the need to access it, please file an issue instead and we'll add your missing functionality as proper Haskell/JavaScript interfaces instead.","title":"What's permitted in foreign import javascript"},{"location":"jsffi/#implementation","text":"This subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code. It's not a required reading for users of the JSFFI feature.","title":"Implementation"},{"location":"jsffi/#syntactic-sugar","text":"As documented in previous sections, one can write foreign import javascript or foreign export javascript clauses in a .hs module. How are they processed? The logic resides in Asterius.JSFFI . First, there is addFFIProcessor , which given a Compiler (defined in ghc-toolkit ), returns a new Compiler and a callback to fetch a stub module. The details of Compiler 's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API. addFFIProcessor adds one functionality to the input Compiler : rewrite parsed Haskell AST and handle the foreign import javascript / foreign export javascript syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal. After the parsed AST is processed, a \"stub module\" of type AsteriusModule is generated and can be later fetched given an AsteriusModuleSymbol . It contains JSFFI related information of type FFIMarshalState . Both AsteriusModule and FFIMarshalState types has Semigroup instance so they can be combined later at link-time.","title":"Syntactic sugar"},{"location":"jsffi/#todo","text":"","title":"TODO"},{"location":"jsffi/#adding-a-jsffi-basic-type","text":"Look at the following places: Asterius.JSFFI module. All JavaScript reference types are uniformly handled as FFI_JSREF , while value types are treated as FFI_VAL . Assuming we are adding a value type. Add logic to: marshalToFFIValueType : Recognize the value type in parsed AST, and translate to FFI_VAL Asterius.Builtins module. Add the corresponding rts_mkXX / rts_getXX builtin functions. They are required for stub functions of foreign export javascript .","title":"Adding a JSFFI basic type"},{"location":"readings/","text":"Reading list Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers. GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API. GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project: Building guide . A tl;dr for this section is our CI scripts. Overview of pipeline : we use the Hooks mechanism (specifically, runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs. How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood. The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work. The runtime system : content regarding the runtime system. Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel Understanding the RealWorld The WebAssembly spec : a useful reference regarding what's already present in WebAssembly. The binaryen C API : binaryen handles WebAssembly code generation. There are a few differences regarding binaryen AST and WebAssembly AST, the most notable ones: binaryen uses a recursive BinaryenExpression which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions. binaryen contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls. The following entries are papers which consume much more time to read, but still quite useful for newcomers: Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks) The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the .tex file to .pdf before reading. The GHC storage manager : Similar to above. Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics. Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code: There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API. When writing build.mk for compiling GHC, add HADDOCK_DOCS = YES to ensure building haddock docs of GHC API, and EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source to enable symbol hyperlinks in the source pages. This will save you tons of time from grep ing the ghc codebase. grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.","title":"Reading list"},{"location":"readings/#reading-list","text":"Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers. GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API. GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project: Building guide . A tl;dr for this section is our CI scripts. Overview of pipeline : we use the Hooks mechanism (specifically, runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs. How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood. The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work. The runtime system : content regarding the runtime system. Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel Understanding the RealWorld The WebAssembly spec : a useful reference regarding what's already present in WebAssembly. The binaryen C API : binaryen handles WebAssembly code generation. There are a few differences regarding binaryen AST and WebAssembly AST, the most notable ones: binaryen uses a recursive BinaryenExpression which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions. binaryen contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls. The following entries are papers which consume much more time to read, but still quite useful for newcomers: Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks) The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the .tex file to .pdf before reading. The GHC storage manager : Similar to above. Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics. Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code: There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API. When writing build.mk for compiling GHC, add HADDOCK_DOCS = YES to ensure building haddock docs of GHC API, and EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source to enable symbol hyperlinks in the source pages. This will save you tons of time from grep ing the ghc codebase. grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.","title":"Reading list"},{"location":"rts-api/","text":"Invoking RTS API in JavaScript For the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to: Allocate memory, create and inspect Haskell closures on the heap. Trigger Haskell evaluation, then retrieve the results back into JavaScript. Use raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones. Here is a simple example. Suppose we have a Main.fact function: fact :: Int -> Int fact 0 = 1 fact n = n * fact (n - 1) The first step is ensuring fact is actually contained in the final WebAssembly binary produced by ahc-link . ahc-link performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually Main_main_closure which corresponds to Main.main ), repeatedly traversing ASTs and including any discovered symbols. So if Main.main does not have a transitive dependency on fact , fact won't be included into the binary. In order to include fact , either use it in some way in main , or supply --extra-root-symbol=Main_fact_closure flag to ahc-link when compiling. The next step is locating the pointer of fact . The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields: staticsSymbolMap maps static data symbols to linear memory absolute addresses, and functionSymbolMap maps function symbols to WebAssembly function table indices. In this case, we can use i.staticsSymbolMap.Main_fact_closure as the pointer value of Main_fact_closure . For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example. Since we'd like to call fact , we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing --asterius-instance-callback=i=>{ ... } to ahc-link , in the callback body, we can use RTS API like this: i.wasmInstance.exports.hs_init(); const argument = i.wasmInstance.exports.rts_mkInt(5); const thunk = i.wasmInstance.exports.rts_apply(i.staticsSymbolMap.Main_fact_closure, argument); const tid = i.wasmInstance.exports.rts_eval(thunk); console.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.getTSOret(tid))); A line-by-line explanation follows: As usual, the first step is calling hs_init to initialize the runtime. Assuming we'd like to calculate fact 5 , we need to build an Int object which value is 5 . We can't directly pass the JavaScript 5 , instead we should call rts_mkInt , which properly allocates a heap object and sets up the info pointer of an Int value. When we need to pass a value of basic type (e.g. Int , StablePtr , etc), we should always call rts_mk* and use the returned pointers to the allocated heap object. Then we can apply fact to 5 by using rts_apply . It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain rts_apply repeatedly until we get a thunk representing the final result. Finally, we call rts_eval , which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions: rts_eval evaluates a thunk of type a to WHNF. rts_evalIO evaluates the result of IO a to WHNF. rts_evalLazyIO evaluates IO a , without forcing the result to WHNF. It is also the default evaluator used by the runtime to run Main.main . rts_evalStableIO evaluates the result of StablePtr (IO a) to WHNF, then return the result as StablePtr a . All rts_eval* functions initiate a new Haskell thread for evaluation, and they return a thread ID. The thread ID is useful for inspecting whether or not evaluation succeeded and what the result is. If we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The rts_get* functions assume the objects are evaluated and won't trigger evaluation. Assuming we stored the thread ID to tid , we can use getTSOret(tid) to retrieve the result. The result is always a pointer to the Haskell heap, so additionally we need to use rts_getInt to retrieve the unboxed Int content to JavaScript. Most users probably don't need to use RTS API manually, since the foreign import / export syntactic sugar and the makeHaskellCallback interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar, foreign import / export is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.","title":"Invoking RTS API in JavaScript"},{"location":"rts-api/#invoking-rts-api-in-javascript","text":"For the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to: Allocate memory, create and inspect Haskell closures on the heap. Trigger Haskell evaluation, then retrieve the results back into JavaScript. Use raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones. Here is a simple example. Suppose we have a Main.fact function: fact :: Int -> Int fact 0 = 1 fact n = n * fact (n - 1) The first step is ensuring fact is actually contained in the final WebAssembly binary produced by ahc-link . ahc-link performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually Main_main_closure which corresponds to Main.main ), repeatedly traversing ASTs and including any discovered symbols. So if Main.main does not have a transitive dependency on fact , fact won't be included into the binary. In order to include fact , either use it in some way in main , or supply --extra-root-symbol=Main_fact_closure flag to ahc-link when compiling. The next step is locating the pointer of fact . The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields: staticsSymbolMap maps static data symbols to linear memory absolute addresses, and functionSymbolMap maps function symbols to WebAssembly function table indices. In this case, we can use i.staticsSymbolMap.Main_fact_closure as the pointer value of Main_fact_closure . For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example. Since we'd like to call fact , we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing --asterius-instance-callback=i=>{ ... } to ahc-link , in the callback body, we can use RTS API like this: i.wasmInstance.exports.hs_init(); const argument = i.wasmInstance.exports.rts_mkInt(5); const thunk = i.wasmInstance.exports.rts_apply(i.staticsSymbolMap.Main_fact_closure, argument); const tid = i.wasmInstance.exports.rts_eval(thunk); console.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.getTSOret(tid))); A line-by-line explanation follows: As usual, the first step is calling hs_init to initialize the runtime. Assuming we'd like to calculate fact 5 , we need to build an Int object which value is 5 . We can't directly pass the JavaScript 5 , instead we should call rts_mkInt , which properly allocates a heap object and sets up the info pointer of an Int value. When we need to pass a value of basic type (e.g. Int , StablePtr , etc), we should always call rts_mk* and use the returned pointers to the allocated heap object. Then we can apply fact to 5 by using rts_apply . It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain rts_apply repeatedly until we get a thunk representing the final result. Finally, we call rts_eval , which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions: rts_eval evaluates a thunk of type a to WHNF. rts_evalIO evaluates the result of IO a to WHNF. rts_evalLazyIO evaluates IO a , without forcing the result to WHNF. It is also the default evaluator used by the runtime to run Main.main . rts_evalStableIO evaluates the result of StablePtr (IO a) to WHNF, then return the result as StablePtr a . All rts_eval* functions initiate a new Haskell thread for evaluation, and they return a thread ID. The thread ID is useful for inspecting whether or not evaluation succeeded and what the result is. If we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The rts_get* functions assume the objects are evaluated and won't trigger evaluation. Assuming we stored the thread ID to tid , we can use getTSOret(tid) to retrieve the result. The result is always a pointer to the Haskell heap, so additionally we need to use rts_getInt to retrieve the unboxed Int content to JavaScript. Most users probably don't need to use RTS API manually, since the foreign import / export syntactic sugar and the makeHaskellCallback interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar, foreign import / export is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.","title":"Invoking RTS API in JavaScript"},{"location":"vault/","text":"The \"Vault\" Asterius provides a \"persistent vault\" feature, which provides a KV store per asterius instance, and the store can be accessed in both Haskell and JavaScript. The vault enables compiled Haskell code to reuse some state, even if the whole asterius instance is wiped and restarted. See GitHub issue 48 for further explanation. The Haskell API is in Asterius.Vault in base : vaultInsert :: JSArrayBuffer -> JSVal -> IO () vaultLookup :: JSArrayBuffer -> IO (Maybe JSVal) vaultDelete :: JSArrayBuffer -> IO () The key of a vault is a JSArrayBuffer , typically converted from a ByteString . The value can be JSVal , which can be coerce ed from any JS* type. In JavaScript, assuming i is the asterius instance, then i.vault is the instance vault. i.vault defaults to empty, and can be passed around, modified and assigned. The i.vault value is a Map object which uses immutable String s converted from ArrayBuffer s as keys. It's only safe to manipulate keys in JavaScript when you're sure the strings only encode Latin-1 characters.","title":"The Vault"},{"location":"vault/#the-vault","text":"Asterius provides a \"persistent vault\" feature, which provides a KV store per asterius instance, and the store can be accessed in both Haskell and JavaScript. The vault enables compiled Haskell code to reuse some state, even if the whole asterius instance is wiped and restarted. See GitHub issue 48 for further explanation. The Haskell API is in Asterius.Vault in base : vaultInsert :: JSArrayBuffer -> JSVal -> IO () vaultLookup :: JSArrayBuffer -> IO (Maybe JSVal) vaultDelete :: JSArrayBuffer -> IO () The key of a vault is a JSArrayBuffer , typically converted from a ByteString . The value can be JSVal , which can be coerce ed from any JS* type. In JavaScript, assuming i is the asterius instance, then i.vault is the instance vault. i.vault defaults to empty, and can be passed around, modified and assigned. The i.vault value is a Map object which uses immutable String s converted from ArrayBuffer s as keys. It's only safe to manipulate keys in JavaScript when you're sure the strings only encode Latin-1 characters.","title":"The \"Vault\""},{"location":"wasm-in-hs/","text":"Writing WebAssembly code in Haskell In Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language. As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file. Directly using Asterius.Types is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block) We now provide an EDSL in Asterius.EDSL to construct an AsteriusFunction . Its core type is EDSL a , and can be composed with a Monad or Monoid interface. Most builtin functions in Asterius.Builtins are already refactored to use this EDSL. Typical usages: \"Allocate\" a parameter/local. Use param or local to obtain an immutable Expression which corresponds to the value of a new parameter/local. There are also mutable variants. An opaque LVal type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an LVal is instantiated, it can be used to read an Expression in the pure world, or set an Expression in the EDSL monad. Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block. When we need named blocks/loops with branching instructions inside, use the block / loop combinators which has the type (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use break' to perform branching. The Label type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label. The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".","title":"Writing WebAssembly code in Haskell"},{"location":"wasm-in-hs/#writing-webassembly-code-in-haskell","text":"In Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language. As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file. Directly using Asterius.Types is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block) We now provide an EDSL in Asterius.EDSL to construct an AsteriusFunction . Its core type is EDSL a , and can be composed with a Monad or Monoid interface. Most builtin functions in Asterius.Builtins are already refactored to use this EDSL. Typical usages: \"Allocate\" a parameter/local. Use param or local to obtain an immutable Expression which corresponds to the value of a new parameter/local. There are also mutable variants. An opaque LVal type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an LVal is instantiated, it can be used to read an Expression in the pure world, or set an Expression in the EDSL monad. Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block. When we need named blocks/loops with branching instructions inside, use the block / loop combinators which has the type (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use break' to perform branching. The Label type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label. The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".","title":"Writing WebAssembly code in Haskell"},{"location":"webassembly/","text":"WebAssembly as a Haskell compilation target There are a few issues to address when compiling Cmm to WebAssembly. Implementing Haskell Stack/Heap The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it. We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC. All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise. Implementing STG machine registers The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of StgRegTable . Handling control flow WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing. The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from hoopl labels to basic blocks and an entry label. Branching happens at the end of each basic block. In-function branching is relatively easier to handle. binaryen provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue #22 for relevant discussion. Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation: Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses br_table or a binary decision tree to branch to the entry block of callee. One WebAssembly function for one CmmProc , and upon CmmCall the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using call_indirect . This approach is actually used by the unregisterised mode of ghc . We're using the latter approach: every CmmProc marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away. Handling relocations When producing a WebAssembly binary, we need to map CLabel s to the precise linear memory locations for CmmStatics or the precise table ids for CmmProc s. They are unknown when compiling individual modules, so binaryen is invoked only when linking, and during compiling we only convert CLabel s to some serializable representation. Currently WebAssembly community has a proposal for linkable object format, and it's prototyped by lld . We'll probably turn to that format and use lld some day, but right now we'll simply stick to our own format for simplicity. The word size story Although wasm64 is scheduled, currently only wasm32 is implemented. However, we are running 64-bit ghc , and there are several places which need extra care: The load/store instructions operate on 64-bit addresses, yet wasm32 use uint32 when indexing into the linear memory. The CmmSwitch labels are 64-bit. CmmCondBranch also checks a 64-bit condition. br_if / br_table operates on uint32 . Only i32 / i64 is supported by wasm32 value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers. We insert instructions for converting between 32/64-bits in the codegen. The binaryen validator also helps checking bit lengths. As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use uint32 . Pages and addresses The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes: CurrentMemory / GrowMemory Memory component of a Module When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count. The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.","title":"WebAssembly as a Haskell compilation target"},{"location":"webassembly/#webassembly-as-a-haskell-compilation-target","text":"There are a few issues to address when compiling Cmm to WebAssembly.","title":"WebAssembly as a Haskell compilation target"},{"location":"webassembly/#implementing-haskell-stackheap","text":"The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it. We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC. All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise.","title":"Implementing Haskell Stack/Heap"},{"location":"webassembly/#implementing-stg-machine-registers","text":"The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of StgRegTable .","title":"Implementing STG machine registers"},{"location":"webassembly/#handling-control-flow","text":"WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing. The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from hoopl labels to basic blocks and an entry label. Branching happens at the end of each basic block. In-function branching is relatively easier to handle. binaryen provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue #22 for relevant discussion. Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation: Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses br_table or a binary decision tree to branch to the entry block of callee. One WebAssembly function for one CmmProc , and upon CmmCall the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using call_indirect . This approach is actually used by the unregisterised mode of ghc . We're using the latter approach: every CmmProc marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away.","title":"Handling control flow"},{"location":"webassembly/#handling-relocations","text":"When producing a WebAssembly binary, we need to map CLabel s to the precise linear memory locations for CmmStatics or the precise table ids for CmmProc s. They are unknown when compiling individual modules, so binaryen is invoked only when linking, and during compiling we only convert CLabel s to some serializable representation. Currently WebAssembly community has a proposal for linkable object format, and it's prototyped by lld . We'll probably turn to that format and use lld some day, but right now we'll simply stick to our own format for simplicity.","title":"Handling relocations"},{"location":"webassembly/#the-word-size-story","text":"Although wasm64 is scheduled, currently only wasm32 is implemented. However, we are running 64-bit ghc , and there are several places which need extra care: The load/store instructions operate on 64-bit addresses, yet wasm32 use uint32 when indexing into the linear memory. The CmmSwitch labels are 64-bit. CmmCondBranch also checks a 64-bit condition. br_if / br_table operates on uint32 . Only i32 / i64 is supported by wasm32 value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers. We insert instructions for converting between 32/64-bits in the codegen. The binaryen validator also helps checking bit lengths. As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use uint32 .","title":"The word size story"},{"location":"webassembly/#pages-and-addresses","text":"The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes: CurrentMemory / GrowMemory Memory component of a Module When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count. The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.","title":"Pages and addresses"}]}